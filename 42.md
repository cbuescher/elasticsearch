## Benchmark One Stop Page

This page should answer the most important questions that you may have w.r.t. to Elasticsearch benchmarks. It is kept in a private repo because we also talk about some internals here.

### Which types of benchmarks are available?

* **Nightly benchmarks** of latest Elasticsearch master are publicly available at [https://elasticsearch-benchmarks.elastic.co/](https://elasticsearch-benchmarks.elastic.co/).

## What time do the nightly benchmarks start? What Elasticsearch commit do they choose?

This is defined in the corresponding Jenkins Jobs: [group-1](https://github.com/elastic/infra/blob/65e533f573b219ed2f21d8bfd30efceda7ab0f29/ci/jjb/elasticsearch-ci/globals/templates/elastic-elasticsearch/macrobenchmarks-group-1.yml#L69) and [group-2](https://github.com/elastic/infra/blob/65e533f573b219ed2f21d8bfd30efceda7ab0f29/ci/jjb/elasticsearch-ci/globals/templates/elastic-elasticsearch/macrobenchmarks-group-2.yml#L69) and [group-3](https://github.com/elastic/infra/blob/65e533f573b219ed2f21d8bfd30efceda7ab0f29/ci/jjb/elasticsearch-ci/globals/templates/elastic-elasticsearch/macrobenchmarks-group-3.yml#L69).

These jobs don't set an effective start date, so night-rally will pick the [current date time as effective start date](https://github.com/elastic/night-rally/blob/a71c4fe3d61015b2bf8654ff88a59efd83052bca/night_rally.sh#L45).

The Elasticsearch revision will be the closest commit to the effective start date (see [--revision in Rally](https://esrally.readthedocs.io/en/stable/command_line_reference.html#revision)). 

### How are the benchmarks run? Can I also execute them?

All macrobenchmarks are run with [Rally](https://github.com/elastic/rally) which is open source. Rally also has a [user documentation](http://esrally.readthedocs.io/en/latest/).

Our benchmark suite is maintained in a separate open source repo, called [rally-tracks](https://github.com/elastic/rally-tracks). The Elasticsearch configurations that we support out of the box for our benchmarks are maintained at [rally-teams](https://github.com/elastic/rally-teams). Again, all this is open source.

We also document our [benchmarking methodology](https://elasticsearch-benchmarks.elastic.co/) publicly.

### Where are the benchmark machines?

See our list of the [current bare metal environments](https://wiki.elastic.co/pages/viewpage.action?pageId=135076508).

### What benchmark suites are available?

* The official benchmark suite of Rally, called [rally-tracks](https://github.com/elastic/rally-tracks) which is open-source.
* A company-internal benchmark suite used for various purposes, called [rally-internal-tracks](https://github.com/elastic/rally-internal-tracks).
* [rally-eventdata-track](https://github.com/elastic/rally-eventdata-track) to simulate simulating event-based data use-cases. It also includes a simulation of the usage patterns of Kibana dashboards.

### What do we do to ensure reproducible results?

1. We only run on bare-metal. The load test driver is physically separated from the benchmark candidate server and all machines are in the same rack and connected via a high throughput network connection.
2. The machines are specially setup to be as silent as possible. If you are interested, check out the [respective playbook](https://github.com/elastic/infra/blob/master/ansible/playbooks/macrobenchmarks_targets.yml) and the associated roles in the infra repo.
3. System software (kernel, JDK) is only updated very seldom and we document each and every upgrade publicly.
4. Rally captures lots of details about the system it runs on so we know for each measurement sample that we store: the exact Elasticsearch version (git hash), JDK version, Rally version and kernel version.
5. We run a set of fixtures before each benchmark run: At least we [drop the page cache and SLAB objects](https://github.com/elastic/night-rally/tree/master/night_rally/fixtures/ansible/roles/drop-caches) and [TRIM the disk](https://github.com/elastic/night-rally/tree/master/night_rally/fixtures/ansible/roles/trim).

### What types of benchmarks are not available?

We usually only run regular benchmark that are mainly focused on the needs of the development team. As such we do not have benchmarks for:

* Very specific system configurations (different file systems, I/O schedulers, ...)
* Very specific configurations of Elasticsearch
* Specific combinations of plugins
* Windows benchmarks
* Benchmarks how Elasticsearch behaves on different types of EC2 instances or instances at other cloud providers

We also do not have any scalability benchmarks (yet). Please also see the [list of open issues](https://github.com/elastic/night-rally/issues) to see what's on the roadmap.

If you are missing a certain benchmark, please go ahead, use Rally and run it. All the tooling is available as open-source and it is well-documented. However, if you think we should run a specific benchmark regularly, please [raise an issue](https://github.com/elastic/night-rally/issues/new).

### Where is the web page for elasticsearch-benchmarks.elastic.co stored?

It is stored in the S3 bucket `elasticsearch-benchmarks.elastic.co` in the AWS Elasticsearch account, US East (N. Virginia) region and hosted via [Google Cloud CDN](https://cloud.google.com/cdn/docs/using-cdn) which expires every [10 minutes](https://github.com/elastic/night-rally/issues/322#issuecomment-708165630).

### My question is not answered

Please [raise an issue](https://github.com/elastic/night-rally/issues/new).
